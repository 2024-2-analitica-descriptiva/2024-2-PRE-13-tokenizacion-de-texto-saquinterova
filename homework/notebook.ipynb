{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input/file2.txt  Electric vehicles are gaining global popularity lately, and along with\n",
      "../files/input/file3.txt  Global solar irradiation is an important variable that can be used to \n",
      "../files/input/file1.txt  It is essential to develop non-precious metal-based alternatives used \n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "import glob\n",
    "\n",
    "\n",
    "def load_data(input_directory):\n",
    "\n",
    "    sequence = []\n",
    "    files = glob.glob(f\"{input_directory}/*\")\n",
    "    for file in files:\n",
    "        with open(file, \"rt\", encoding=\"utf-8\") as f:\n",
    "            raw_text = f.read()\n",
    "            sequence.append((file, raw_text))\n",
    "    return sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "for file, text in sequence:\n",
    "    print(f\"{file}  {text[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input/file2.txt  electric vehicles are gaining global popularity lately, and along with\n",
      "../files/input/file3.txt  global solar irradiation is an important variable that can be used to \n",
      "../files/input/file1.txt  it is essential to develop non-precious metal-based alternatives used \n"
     ]
    }
   ],
   "source": [
    "# Clean text\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(sequence):\n",
    "    cleaned_sequence = []\n",
    "    for file, text in sequence:\n",
    "        cleaned_text = re.sub(r\"\\n\", \" \", text)\n",
    "        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n",
    "        cleaned_text = cleaned_text.strip()\n",
    "        cleaned_text = cleaned_text.lower()\n",
    "        cleaned_sequence.append((file, cleaned_text))\n",
    "    return cleaned_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "for file, text in cleaned_sequence:\n",
    "    print(f\"{file}  {text[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Electric vehicles are gaining global popularity lately, and along with it, \\nefficient battery thermal management systems (BTMS) are also gaining \\ntraction amongst the research community. Phase change material (PCM) based \\nBTMS can be an attractive solution due to its high energy density and \\nisothermal energy exchange. However, pure PCM has some drawbacks like \\nlow thermal conductivity, volume expansion, and leakage during phase \\nchange. A shape stable composite PCM (SSCPCM) resolves these drawbacks \\nbut is an expensive solution due to the high cost of conventional \\nsupporting materials. Biochar (BC) based SSCPCM developed in this study \\ncan be a cheap and sustainable solution for BTMS. The characterization \\nstudies are carried out for combination of pure PCM (Myristyl Alcohol) \\nand biochar at various loadings of 6%, 12%, 18%, and 24% by weight, \\nusing Fourier transform infrared analysis (FT-IR), X-ray diffraction \\n(XRD) analysis, scanning electron microscopy (SEM), particle size analysis \\n(PSA), differential scanning calorimetry (DSC), and thermogravimetric \\nanalysis (TGA). The shape stability studies reveal that the PCM with \\nminimum of 24% biochar (PCM-BC24) is shape stable. The thermal \\nconductivities and effusivities of pure and shape-stable composite \\nPCMs are also studied. Enhancement in thermal conductivity of \\nPCM-BC24 is studied with the addition of multi-walled carbon \\nnanotubes (MWCNT) in 0.5% and 1% concentrations. FT-IR and XRD \\nresults reveal that the interaction of biochar and MWCNT with pure \\nPCM is purely physical and chemically stable. The degree of \\nsupercooling is reduced by 19.26%, 23.49%, and 25.17% for \\nPCM-BC24 with 1% MWCNT compared to pure PCM at a heating rate of 5.0, \\n7.5, and 10 °C/min, respectively. Thermal conductivity and effusivity \\nof PCM-BC24 with 1% MWCNT are 458.72% and 146.25% higher than the \\npure PCM, respectively. The TGA results reveal that PCMs thermal \\nstability is not adversely affected by the addition of BC & MWCNT. \\nFurthermore, an ANFIS model is developed to predict the heat flow (mW/mg) \\nvalues of PCM samples and found that the generalized bell-shaped input and \\nlinear output membership function is best suitable with a coefficient of \\ndetermination (R2) of 0.971.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input/file2.txt  electric vehicles are gaining global popularity lately, and along with\n",
      "../files/input/file3.txt  global solar irradiation is an important variable that can be used to \n",
      "../files/input/file1.txt  it is essential to develop non-precious metal-based alternatives used \n"
     ]
    }
   ],
   "source": [
    "# Clean text\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(sequence):\n",
    "    cleaned_sequence = []\n",
    "    for file, text in sequence:\n",
    "        cleaned_text = re.sub(r\"\\n\", \" \", text)\n",
    "        cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n",
    "        cleaned_text = cleaned_text.strip()\n",
    "        cleaned_text = cleaned_text.lower()\n",
    "        cleaned_sequence.append((file, cleaned_text))\n",
    "    return cleaned_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "for file, text in cleaned_sequence:\n",
    "    print(f\"{file}  {text[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input/file2.txt  electric vehicles are gaining global popularity lately , and along wit\n",
      "../files/input/file3.txt  global solar irradiation is an important variable that can be used to \n",
      "../files/input/file1.txt  it is essential to develop non-precious metal-based alternatives used \n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# nltk.download(\"punkt_tab\")\n",
    "\n",
    "\n",
    "def tokenize(sequence):\n",
    "    tokenized_sequence = []\n",
    "    for file, text in sequence:\n",
    "        tokens = word_tokenize(text)\n",
    "        tokenized_sequence.append((file, tokens))\n",
    "    return tokenized_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "for file, text in tokenized_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input/file2.txt  electric vehicles are gaining global popularity lately and along with \n",
      "../files/input/file3.txt  global solar irradiation is an important variable that can be used to \n",
      "../files/input/file1.txt  it is essential to develop alternatives used in hydrogen evolution rea\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remoción de datos ruidosos (Opcion A)\n",
    "def filter_tokens_a(sequence):\n",
    "    \"\"\"Esta solucion puede perder tokens que contienen caracteres no alfabeticos\"\"\"\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [token for token in tokens if token.isalpha()]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_a(tokenized_sequence)\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input/file2.txt  electric vehicles are gaining global popularity lately and along with \n",
      "../files/input/file3.txt  global solar irradiation is an important variable that can be used to \n",
      "../files/input/file1.txt  it is essential to develop non precious metal based alternatives used \n"
     ]
    }
   ],
   "source": [
    "# Remoción de datos ruidosos (Opcion B)\n",
    "def filter_tokens_b(sequence):\n",
    "    \"\"\"Esta solucion puede perder tokens que contienen caracteres no alfabeticos\"\"\"\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [re.sub(r\"[^a-zA-Z\\s]\", \" \", token)\n",
    "                           for token in tokens]\n",
    "        filtered_tokens = [re.sub(r\"\\s+\", \" \", token)\n",
    "                           for token in filtered_tokens]\n",
    "        filtered_tokens = [token.strip() for token in filtered_tokens]\n",
    "        filtered_tokens = [token for token in filtered_tokens if token != \"\"]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sqv/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/input/file2.txt  electric vehicles gaining global popularity lately along efficient bat\n",
      "../files/input/file3.txt  global solar irradiation important variable used determine suitability\n",
      "../files/input/file1.txt  essential develop non precious metal based alternatives used hydrogen \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove the stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "def remove_stopwords(sequence):\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    filtered_sequence = []\n",
    "    for file, tokens in sequence:\n",
    "        filtered_tokens = [\n",
    "            token for token in tokens if token not in stop_words]\n",
    "        filtered_sequence.append((file, filtered_tokens))\n",
    "    return filtered_sequence\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "filtered_sequence = remove_stopwords(filtered_sequence)\n",
    "for file, text in filtered_sequence:\n",
    "    print(f\"{file}  {' '.join(text)[:70]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "\n",
    "def save_data(output_directory, sequence):\n",
    "\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    for file, tokens in sequence:\n",
    "        with open(\n",
    "            f\"{output_directory}/{file.split('/')[-1]}\",\n",
    "            \"wt\",\n",
    "            encoding=\"utf-8\",\n",
    "        ) as f:\n",
    "            f.write(textwrap.fill(\" \".join(tokens), width=70))\n",
    "\n",
    "\n",
    "sequence = load_data(input_directory=\"../files/input\")\n",
    "cleaned_sequence = clean_text(sequence)\n",
    "tokenized_sequence = tokenize(cleaned_sequence)\n",
    "filtered_sequence = filter_tokens_b(tokenized_sequence)\n",
    "filtered_sequence = remove_stopwords(filtered_sequence)\n",
    "save_data(output_directory=\"../files/output\", sequence=filtered_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
